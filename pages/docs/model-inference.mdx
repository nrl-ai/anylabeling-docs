# Auto Labeling - Model Inference

Adding model inference is a key to automate labeling tasks. The early version of AnyLabeling supports Segment Anything and YOLO models. The Segment Anything models and the first YOLOv5 model were added. Other YOLOv5 and YOLOv8 models were added by [Henry](https://github.com/hdnh2006). The model inference architecture is shown below:

![Model inference architecture](https://aicurious.io/posts-data/2023-04-22-create-a-segment-anything-labeling-tool-any-labeling/model-inference.svg)

In the architecture of **AnyLabeling**, [LabelingWidget](https://github.com/vietanhdev/anylabeling/blob/master/anylabeling/views/labeling/label_widget.py) is the main widget for any features. The drawing area is handled by class [Canvas](https://github.com/vietanhdev/anylabeling/blob/master/anylabeling/views/labeling/widgets/canvas.py). We added [AutoLabelingWidget](https://github.com/vietanhdev/anylabeling/blob/master/anylabeling/views/labeling/widgets/auto_labeling/auto_labeling.py) as the main widget for auto labeling feature and [ModelManager](https://github.com/vietanhdev/anylabeling/blob/master/anylabeling/services/auto_labeling/model_manager.py) for managing and running AI models.

**Boost the speed:**

Because the calculation of the Encoder takes time, we can cache the result and also do pre-calculation for the Encoder on future images. This will reduce the time user need to wait for Encoder to run.

- For the caching, we added an LRU cache to save the results of the Encoder. The images are saved in the cache with the key is the label path. When an image embedding is present in the cache, the Encoder will not be run again, which can save time a lot. The cache size is 10 images by default.

- For the pre-calculation, a thread is created to run the Encoder for the next images. When a new image is loaded, it and the next images will be sent to the worker thread for Encoder calculation. After that, the image embedding will be cached in the LRU cache above. If the image is already in the cache, the worker thread will skip it.
